# Business Intelligence and Deep Learning Project

## Project Overview
This project merges Business Intelligence (BI) and Deep Learning to scrap and classify news data into "Fake" and "Real" categories. The project is divided into phases for efficient development and execution.


# Progress Checklist:

### I) Setting up the Environment
- Docker: Containerization of the project (Done) âœ”
- GitHub: Version control for collaborative development (Done) âœ”
- MongoDB: Data storage and management (Done) âœ”

### II) Scraping Script
#### Data Scraping Optimization
- Error logging (Done) âœ”
- Custom headers (In Progress) ðŸ”§
- User-agent spoofing (In Progress) ðŸ”§
- Request throttling (In Progress) ðŸ”§
- Tor proxy integration (In Progress) ðŸ”§

#### Data Storage and Management in MongoDB
- Data Insertion (Done) âœ”
- Duplicate Checking (Done) âœ”
- Data Query (Done) âœ”
- Data Purging (Done) âœ”

### III) Data Classification (Fake/Real)
- Data Preprocessing (To Do) âœ˜
- Model Development (To Do) âœ˜
- Model Evaluation (To Do) âœ˜
- Integration (To Do) âœ˜

### IV) Data Visualization with Django
- Django Web Application (To Do) âœ˜
- User-friendly Dashboards (To Do) âœ˜
- User Authentication (To Do) âœ˜
- Data Access Control (To Do) âœ˜
- Deployment (To Do) âœ˜

# Script Usage:
To manage data in MongoDB using the provided script, you can use the following command-line arguments:

- `--scrap`: Use this argument to initiate data scraping. Specify the desired language for scraping by providing one of the supported language codes (e.g., "EN" for English, "FR" for French, "ES" for Spanish). For example:
  `python script.py --scrap EN`
- `--query`: Use this argument to query the MongoDB collection and retrieve stored data. Execute it as follows:
  `python script.py --query`
- `--purge`: Clear (purge) the MongoDB collection and remove all data by using this argument:
  `python script.py --purge`


